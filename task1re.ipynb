{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "11d2696aa44a2f0a370d91ea6517e7b889927749bc2cd16347a8ce4083dc1b7d"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "task1re.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooW5LQ6rdfYK"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.feature_selection import SelectKBest, chi2, RFECV, RFE, SelectFromModel\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpezHrtfk1Ah",
        "outputId": "3121900e-1da8-4fcc-b965-2f5da85f844f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IALC37a0dfYS"
      },
      "source": [
        "# 1. Load training data and test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5YoPW9ZdfYV"
      },
      "source": [
        "## 1.1 Read the csv files and get an overview of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhh0V-nkdfYW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "add8042e-7719-4792-c68b-745cfa5b68c3"
      },
      "source": [
        "X_df = pd.read_csv('/content/drive/MyDrive/AML/task1/X_train.csv') # df stands for dataframe\n",
        "y_df = pd.read_csv('/content/drive/MyDrive/AML/task1/y_train.csv')\n",
        "X_test_df = pd.read_csv('/content/drive/MyDrive/AML/task1/X_test.csv')\n",
        "print(\"Dimension of X: {}\".format(X_df.shape))\n",
        "print(\"Dimension of y: {}\".format(y_df.shape))\n",
        "X_df.tail()\n",
        "y_df.tail()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of X: (1212, 833)\n",
            "Dimension of y: (1212, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1207</th>\n",
              "      <td>1207.0</td>\n",
              "      <td>67.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1208</th>\n",
              "      <td>1208.0</td>\n",
              "      <td>48.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1209</th>\n",
              "      <td>1209.0</td>\n",
              "      <td>82.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1210</th>\n",
              "      <td>1210.0</td>\n",
              "      <td>76.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1211</th>\n",
              "      <td>1211.0</td>\n",
              "      <td>81.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id     y\n",
              "1207  1207.0  67.0\n",
              "1208  1208.0  48.0\n",
              "1209  1209.0  82.0\n",
              "1210  1210.0  76.0\n",
              "1211  1211.0  81.0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFjGgi4IdfYZ"
      },
      "source": [
        "## 1.2 Get rid of the id column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnkLRmSodfYa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6eecdcd-3068-49c3-9906-c832d4b0374b"
      },
      "source": [
        "X_data = X_df.iloc[:,1:]\n",
        "y_data = y_df.iloc[:,1:]\n",
        "X_test = X_test_df.iloc[:, 1:]\n",
        "print(\"X_data shape:\", X_data.shape)\n",
        "print(\"y_data shape:\", y_data.shape)\n",
        "print(\"X_test shape:\", X_test.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_data shape: (1212, 832)\n",
            "y_data shape: (1212, 1)\n",
            "X_test shape: (776, 832)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ4oR4S8dfYb"
      },
      "source": [
        "# 2. Fill the missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8RYQ2ewdfYc"
      },
      "source": [
        "## 2.1 Get to know how many missing values there are"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1vrYI34dfYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc492ca-8378-40ea-ebda-f56c77350b79"
      },
      "source": [
        "feature_missing_values = X_data.isna().sum(axis = 0)\n",
        "print (\"Number of missing values for each feature:\\n\", feature_missing_values)\n",
        "\n",
        "record_missing_values = X_data.isna().sum(axis = 1)\n",
        "print (\"Number of missing values for each record:\\n\", record_missing_values)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of missing values for each feature:\n",
            " x0       94\n",
            "x1       98\n",
            "x2       95\n",
            "x3      106\n",
            "x4       95\n",
            "       ... \n",
            "x827    103\n",
            "x828     97\n",
            "x829    100\n",
            "x830     88\n",
            "x831    121\n",
            "Length: 832, dtype: int64\n",
            "Number of missing values for each record:\n",
            " 0       59\n",
            "1       67\n",
            "2       61\n",
            "3       57\n",
            "4       62\n",
            "        ..\n",
            "1207    55\n",
            "1208    76\n",
            "1209    60\n",
            "1210    51\n",
            "1211    69\n",
            "Length: 1212, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mwUC84WdfYf"
      },
      "source": [
        "## 2.2 Using median"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9dCin5bdfYg"
      },
      "source": [
        "# X_data_1 = X_data.fillna(X_data.median())\n",
        "# X_test_1 = X_test.fillna(X_test.median())\n",
        "# missing_values = X_data_1.isna().any() # any(): Return whether any element is True, potentially over an axis.\n",
        "# print (\"After filling, number of missing values for each feature:\\n\", missing_values)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfFT_rYFdfYh"
      },
      "source": [
        "## 2.3 Using KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTNraXPudfYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54200a91-8870-4865-a834-be80b304a2b8"
      },
      "source": [
        "# To use KNN imputer, we need to first normalize our data so the distance measure of each feature is the same\n",
        "scaler = RobustScaler(quantile_range=(10, 90))\n",
        "X_data_sc = pd.DataFrame(scaler.fit_transform(X_data), columns=X_data.columns)\n",
        "X_test_sc = pd.DataFrame(scaler.fit_transform(X_test), columns=X_test.columns)\n",
        "\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "X_data_1 = pd.DataFrame(imputer.fit_transform(X_data_sc), columns=X_data.columns)\n",
        "X_test_1 = pd.DataFrame(imputer.fit_transform(X_test_sc), columns=X_test.columns)\n",
        "\n",
        "print(\"Missing values\", X_data_1.isna().any())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values x0      False\n",
            "x1      False\n",
            "x2      False\n",
            "x3      False\n",
            "x4      False\n",
            "        ...  \n",
            "x827    False\n",
            "x828    False\n",
            "x829    False\n",
            "x830    False\n",
            "x831    False\n",
            "Length: 832, dtype: bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppDH6lyLdfYj"
      },
      "source": [
        "# 3. Outlier detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvOm9H3sdfYj"
      },
      "source": [
        "## 3.1 Using IsolationForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQOicDn4dfYj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f554c6f-922c-4b75-f802-09235b39930b"
      },
      "source": [
        "iso_forest = IsolationForest(n_estimators=500, contamination=0.05)\n",
        "iso_forest = iso_forest.fit(X_data_1)\n",
        "isof_outliers = iso_forest.predict(X_data_1)\n",
        "X_data_2 = X_data_1.iloc[isof_outliers == 1, :]\n",
        "y_data = y_data.iloc[isof_outliers == 1].values\n",
        "print(X_data_2.shape)\n",
        "\n",
        "X_test_2 = X_test_1\n",
        "\n",
        "# # Delete nothing\n",
        "# X_data_2 = X_data_1\n",
        "# X_test_2 = X_test_1\n",
        "# y_data = y_data.values"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1151, 832)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qd7oA0Kdu1rt",
        "outputId": "a46832d0-2500-4730-eafd-220abe1d3309"
      },
      "source": [
        "X_data_2.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x0</th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x10</th>\n",
              "      <th>x11</th>\n",
              "      <th>x12</th>\n",
              "      <th>x13</th>\n",
              "      <th>x14</th>\n",
              "      <th>x15</th>\n",
              "      <th>x16</th>\n",
              "      <th>x17</th>\n",
              "      <th>x18</th>\n",
              "      <th>x19</th>\n",
              "      <th>x20</th>\n",
              "      <th>x21</th>\n",
              "      <th>x22</th>\n",
              "      <th>x23</th>\n",
              "      <th>x24</th>\n",
              "      <th>x25</th>\n",
              "      <th>x26</th>\n",
              "      <th>x27</th>\n",
              "      <th>x28</th>\n",
              "      <th>x29</th>\n",
              "      <th>x30</th>\n",
              "      <th>x31</th>\n",
              "      <th>x32</th>\n",
              "      <th>x33</th>\n",
              "      <th>x34</th>\n",
              "      <th>x35</th>\n",
              "      <th>x36</th>\n",
              "      <th>x37</th>\n",
              "      <th>x38</th>\n",
              "      <th>x39</th>\n",
              "      <th>...</th>\n",
              "      <th>x792</th>\n",
              "      <th>x793</th>\n",
              "      <th>x794</th>\n",
              "      <th>x795</th>\n",
              "      <th>x796</th>\n",
              "      <th>x797</th>\n",
              "      <th>x798</th>\n",
              "      <th>x799</th>\n",
              "      <th>x800</th>\n",
              "      <th>x801</th>\n",
              "      <th>x802</th>\n",
              "      <th>x803</th>\n",
              "      <th>x804</th>\n",
              "      <th>x805</th>\n",
              "      <th>x806</th>\n",
              "      <th>x807</th>\n",
              "      <th>x808</th>\n",
              "      <th>x809</th>\n",
              "      <th>x810</th>\n",
              "      <th>x811</th>\n",
              "      <th>x812</th>\n",
              "      <th>x813</th>\n",
              "      <th>x814</th>\n",
              "      <th>x815</th>\n",
              "      <th>x816</th>\n",
              "      <th>x817</th>\n",
              "      <th>x818</th>\n",
              "      <th>x819</th>\n",
              "      <th>x820</th>\n",
              "      <th>x821</th>\n",
              "      <th>x822</th>\n",
              "      <th>x823</th>\n",
              "      <th>x824</th>\n",
              "      <th>x825</th>\n",
              "      <th>x826</th>\n",
              "      <th>x827</th>\n",
              "      <th>x828</th>\n",
              "      <th>x829</th>\n",
              "      <th>x830</th>\n",
              "      <th>x831</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.366254</td>\n",
              "      <td>-0.602537</td>\n",
              "      <td>0.237168</td>\n",
              "      <td>-0.246672</td>\n",
              "      <td>0.646918</td>\n",
              "      <td>-0.356928</td>\n",
              "      <td>0.614377</td>\n",
              "      <td>-0.332445</td>\n",
              "      <td>0.563801</td>\n",
              "      <td>-0.302874</td>\n",
              "      <td>-0.498416</td>\n",
              "      <td>0.212626</td>\n",
              "      <td>-0.484550</td>\n",
              "      <td>-0.230231</td>\n",
              "      <td>-0.443511</td>\n",
              "      <td>0.323738</td>\n",
              "      <td>0.527316</td>\n",
              "      <td>-0.560667</td>\n",
              "      <td>-0.057300</td>\n",
              "      <td>-0.398784</td>\n",
              "      <td>0.331705</td>\n",
              "      <td>0.936314</td>\n",
              "      <td>0.139309</td>\n",
              "      <td>0.166117</td>\n",
              "      <td>-0.120616</td>\n",
              "      <td>-0.483488</td>\n",
              "      <td>-0.133835</td>\n",
              "      <td>-0.379148</td>\n",
              "      <td>-0.522631</td>\n",
              "      <td>0.185912</td>\n",
              "      <td>-0.310709</td>\n",
              "      <td>0.401079</td>\n",
              "      <td>-0.058608</td>\n",
              "      <td>-0.065739</td>\n",
              "      <td>0.219344</td>\n",
              "      <td>0.338877</td>\n",
              "      <td>-0.521471</td>\n",
              "      <td>-0.050881</td>\n",
              "      <td>0.821375</td>\n",
              "      <td>-0.206204</td>\n",
              "      <td>...</td>\n",
              "      <td>0.091529</td>\n",
              "      <td>0.354864</td>\n",
              "      <td>-0.000498</td>\n",
              "      <td>-0.166341</td>\n",
              "      <td>0.104771</td>\n",
              "      <td>-0.160049</td>\n",
              "      <td>0.537924</td>\n",
              "      <td>0.637074</td>\n",
              "      <td>-0.044632</td>\n",
              "      <td>0.357295</td>\n",
              "      <td>0.120632</td>\n",
              "      <td>-0.733933</td>\n",
              "      <td>0.301748</td>\n",
              "      <td>-0.519026</td>\n",
              "      <td>0.151594</td>\n",
              "      <td>-0.355137</td>\n",
              "      <td>0.804673</td>\n",
              "      <td>-0.037777</td>\n",
              "      <td>0.380540</td>\n",
              "      <td>0.172868</td>\n",
              "      <td>-0.507662</td>\n",
              "      <td>0.038349</td>\n",
              "      <td>-0.128503</td>\n",
              "      <td>-0.033035</td>\n",
              "      <td>0.065428</td>\n",
              "      <td>-0.471241</td>\n",
              "      <td>0.332334</td>\n",
              "      <td>-0.192552</td>\n",
              "      <td>0.210712</td>\n",
              "      <td>0.117579</td>\n",
              "      <td>-0.318885</td>\n",
              "      <td>0.050707</td>\n",
              "      <td>-0.196689</td>\n",
              "      <td>0.117974</td>\n",
              "      <td>0.325079</td>\n",
              "      <td>0.303604</td>\n",
              "      <td>-0.566476</td>\n",
              "      <td>-0.176145</td>\n",
              "      <td>-0.575897</td>\n",
              "      <td>-0.226159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.432092</td>\n",
              "      <td>0.458436</td>\n",
              "      <td>-0.147386</td>\n",
              "      <td>-0.553701</td>\n",
              "      <td>-0.306695</td>\n",
              "      <td>-0.351380</td>\n",
              "      <td>-0.038824</td>\n",
              "      <td>0.109042</td>\n",
              "      <td>0.104857</td>\n",
              "      <td>-0.026660</td>\n",
              "      <td>0.175691</td>\n",
              "      <td>-0.213002</td>\n",
              "      <td>-0.400969</td>\n",
              "      <td>-0.706979</td>\n",
              "      <td>0.123232</td>\n",
              "      <td>0.132832</td>\n",
              "      <td>-0.571213</td>\n",
              "      <td>-0.142955</td>\n",
              "      <td>-0.208848</td>\n",
              "      <td>0.056125</td>\n",
              "      <td>0.031362</td>\n",
              "      <td>0.392277</td>\n",
              "      <td>-0.206804</td>\n",
              "      <td>-1.281982</td>\n",
              "      <td>0.533658</td>\n",
              "      <td>0.041791</td>\n",
              "      <td>0.163144</td>\n",
              "      <td>0.296507</td>\n",
              "      <td>-0.104647</td>\n",
              "      <td>0.064881</td>\n",
              "      <td>0.664561</td>\n",
              "      <td>-0.462420</td>\n",
              "      <td>0.311602</td>\n",
              "      <td>-0.083953</td>\n",
              "      <td>0.057019</td>\n",
              "      <td>-0.313337</td>\n",
              "      <td>0.181062</td>\n",
              "      <td>-0.149937</td>\n",
              "      <td>-0.080653</td>\n",
              "      <td>-0.422615</td>\n",
              "      <td>...</td>\n",
              "      <td>0.930956</td>\n",
              "      <td>-0.404625</td>\n",
              "      <td>-0.626460</td>\n",
              "      <td>0.177020</td>\n",
              "      <td>-0.144440</td>\n",
              "      <td>-0.184671</td>\n",
              "      <td>-0.553214</td>\n",
              "      <td>-0.199383</td>\n",
              "      <td>0.067927</td>\n",
              "      <td>-0.024507</td>\n",
              "      <td>-0.071273</td>\n",
              "      <td>-0.179701</td>\n",
              "      <td>-0.572265</td>\n",
              "      <td>-0.311823</td>\n",
              "      <td>-0.208124</td>\n",
              "      <td>0.152407</td>\n",
              "      <td>-0.187030</td>\n",
              "      <td>-0.347608</td>\n",
              "      <td>0.176291</td>\n",
              "      <td>-0.144937</td>\n",
              "      <td>0.297918</td>\n",
              "      <td>0.077217</td>\n",
              "      <td>0.084467</td>\n",
              "      <td>-0.432927</td>\n",
              "      <td>-0.368816</td>\n",
              "      <td>-0.022950</td>\n",
              "      <td>0.410962</td>\n",
              "      <td>0.504689</td>\n",
              "      <td>0.473242</td>\n",
              "      <td>-0.125366</td>\n",
              "      <td>-0.390869</td>\n",
              "      <td>-0.080001</td>\n",
              "      <td>-0.400141</td>\n",
              "      <td>0.271402</td>\n",
              "      <td>0.092331</td>\n",
              "      <td>-0.731324</td>\n",
              "      <td>0.275481</td>\n",
              "      <td>-0.381353</td>\n",
              "      <td>-0.778377</td>\n",
              "      <td>-0.086109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.167169</td>\n",
              "      <td>-0.361734</td>\n",
              "      <td>0.396267</td>\n",
              "      <td>-0.238947</td>\n",
              "      <td>-0.019179</td>\n",
              "      <td>-0.669567</td>\n",
              "      <td>-0.078957</td>\n",
              "      <td>0.639629</td>\n",
              "      <td>0.244143</td>\n",
              "      <td>-0.432669</td>\n",
              "      <td>0.592228</td>\n",
              "      <td>0.613683</td>\n",
              "      <td>0.515475</td>\n",
              "      <td>-0.628716</td>\n",
              "      <td>0.455264</td>\n",
              "      <td>0.355937</td>\n",
              "      <td>-0.585780</td>\n",
              "      <td>-0.062891</td>\n",
              "      <td>0.372641</td>\n",
              "      <td>0.254074</td>\n",
              "      <td>-0.154041</td>\n",
              "      <td>-0.327385</td>\n",
              "      <td>0.073526</td>\n",
              "      <td>0.140675</td>\n",
              "      <td>0.011798</td>\n",
              "      <td>-0.146518</td>\n",
              "      <td>-0.484218</td>\n",
              "      <td>0.285343</td>\n",
              "      <td>0.736146</td>\n",
              "      <td>0.557712</td>\n",
              "      <td>0.024150</td>\n",
              "      <td>-0.578573</td>\n",
              "      <td>0.268679</td>\n",
              "      <td>-0.344200</td>\n",
              "      <td>0.603555</td>\n",
              "      <td>0.328378</td>\n",
              "      <td>-0.417409</td>\n",
              "      <td>-0.164655</td>\n",
              "      <td>0.181360</td>\n",
              "      <td>0.822299</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.005846</td>\n",
              "      <td>0.111864</td>\n",
              "      <td>0.428670</td>\n",
              "      <td>0.284042</td>\n",
              "      <td>0.409506</td>\n",
              "      <td>0.331444</td>\n",
              "      <td>0.453075</td>\n",
              "      <td>-0.334999</td>\n",
              "      <td>0.063464</td>\n",
              "      <td>0.487918</td>\n",
              "      <td>-0.103585</td>\n",
              "      <td>0.208841</td>\n",
              "      <td>-0.609823</td>\n",
              "      <td>-0.486181</td>\n",
              "      <td>-0.146785</td>\n",
              "      <td>0.430425</td>\n",
              "      <td>-0.408727</td>\n",
              "      <td>0.660101</td>\n",
              "      <td>0.437674</td>\n",
              "      <td>0.221476</td>\n",
              "      <td>-0.279948</td>\n",
              "      <td>0.966123</td>\n",
              "      <td>-0.044372</td>\n",
              "      <td>0.514427</td>\n",
              "      <td>-0.734786</td>\n",
              "      <td>-0.081034</td>\n",
              "      <td>0.355136</td>\n",
              "      <td>0.088157</td>\n",
              "      <td>-0.825760</td>\n",
              "      <td>-0.216536</td>\n",
              "      <td>-0.232344</td>\n",
              "      <td>-0.380367</td>\n",
              "      <td>0.835558</td>\n",
              "      <td>0.049827</td>\n",
              "      <td>0.099136</td>\n",
              "      <td>0.321395</td>\n",
              "      <td>0.096218</td>\n",
              "      <td>-0.320239</td>\n",
              "      <td>0.080176</td>\n",
              "      <td>0.040857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.351395</td>\n",
              "      <td>0.289232</td>\n",
              "      <td>0.293071</td>\n",
              "      <td>-0.062916</td>\n",
              "      <td>0.311761</td>\n",
              "      <td>0.080699</td>\n",
              "      <td>0.063625</td>\n",
              "      <td>-0.139039</td>\n",
              "      <td>-0.100231</td>\n",
              "      <td>0.288177</td>\n",
              "      <td>0.384312</td>\n",
              "      <td>0.269270</td>\n",
              "      <td>0.249566</td>\n",
              "      <td>0.822805</td>\n",
              "      <td>-0.000842</td>\n",
              "      <td>0.574645</td>\n",
              "      <td>-0.094707</td>\n",
              "      <td>0.411075</td>\n",
              "      <td>-0.286924</td>\n",
              "      <td>-0.165425</td>\n",
              "      <td>0.175779</td>\n",
              "      <td>-0.609105</td>\n",
              "      <td>0.714758</td>\n",
              "      <td>-0.210875</td>\n",
              "      <td>0.104949</td>\n",
              "      <td>0.039135</td>\n",
              "      <td>0.280088</td>\n",
              "      <td>0.179142</td>\n",
              "      <td>-0.102233</td>\n",
              "      <td>-0.585132</td>\n",
              "      <td>-0.246189</td>\n",
              "      <td>0.467543</td>\n",
              "      <td>-0.401984</td>\n",
              "      <td>0.312369</td>\n",
              "      <td>-0.173118</td>\n",
              "      <td>0.057036</td>\n",
              "      <td>0.127081</td>\n",
              "      <td>-0.392826</td>\n",
              "      <td>-0.084236</td>\n",
              "      <td>-0.082451</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.144195</td>\n",
              "      <td>-0.420541</td>\n",
              "      <td>0.516235</td>\n",
              "      <td>-0.184277</td>\n",
              "      <td>-0.147865</td>\n",
              "      <td>0.208632</td>\n",
              "      <td>-0.180598</td>\n",
              "      <td>-0.184437</td>\n",
              "      <td>0.017012</td>\n",
              "      <td>-0.357609</td>\n",
              "      <td>-0.045442</td>\n",
              "      <td>-0.037543</td>\n",
              "      <td>0.173530</td>\n",
              "      <td>-0.061712</td>\n",
              "      <td>-0.401402</td>\n",
              "      <td>0.534702</td>\n",
              "      <td>-0.702003</td>\n",
              "      <td>0.322825</td>\n",
              "      <td>0.134834</td>\n",
              "      <td>0.012196</td>\n",
              "      <td>0.369852</td>\n",
              "      <td>0.682798</td>\n",
              "      <td>-0.024586</td>\n",
              "      <td>0.559903</td>\n",
              "      <td>0.846660</td>\n",
              "      <td>-0.513810</td>\n",
              "      <td>-0.317874</td>\n",
              "      <td>-0.096279</td>\n",
              "      <td>0.043405</td>\n",
              "      <td>0.098081</td>\n",
              "      <td>-0.369659</td>\n",
              "      <td>0.215428</td>\n",
              "      <td>-0.085858</td>\n",
              "      <td>0.009466</td>\n",
              "      <td>0.110210</td>\n",
              "      <td>0.321365</td>\n",
              "      <td>0.404988</td>\n",
              "      <td>-0.001046</td>\n",
              "      <td>-0.372933</td>\n",
              "      <td>0.545064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.042825</td>\n",
              "      <td>-0.546083</td>\n",
              "      <td>0.238445</td>\n",
              "      <td>-0.584761</td>\n",
              "      <td>-0.027881</td>\n",
              "      <td>0.074732</td>\n",
              "      <td>0.082182</td>\n",
              "      <td>0.439288</td>\n",
              "      <td>-0.187196</td>\n",
              "      <td>0.559747</td>\n",
              "      <td>0.650666</td>\n",
              "      <td>0.452827</td>\n",
              "      <td>0.471855</td>\n",
              "      <td>-0.413128</td>\n",
              "      <td>0.290864</td>\n",
              "      <td>-0.179733</td>\n",
              "      <td>-0.260738</td>\n",
              "      <td>-0.019663</td>\n",
              "      <td>-0.040849</td>\n",
              "      <td>-0.371956</td>\n",
              "      <td>-0.245471</td>\n",
              "      <td>0.418760</td>\n",
              "      <td>0.957861</td>\n",
              "      <td>-0.375566</td>\n",
              "      <td>-0.341911</td>\n",
              "      <td>0.102844</td>\n",
              "      <td>-0.428553</td>\n",
              "      <td>0.590769</td>\n",
              "      <td>-0.052330</td>\n",
              "      <td>0.450305</td>\n",
              "      <td>0.191042</td>\n",
              "      <td>-0.205598</td>\n",
              "      <td>0.016183</td>\n",
              "      <td>0.367967</td>\n",
              "      <td>0.325781</td>\n",
              "      <td>0.362794</td>\n",
              "      <td>-0.556797</td>\n",
              "      <td>0.112994</td>\n",
              "      <td>0.464433</td>\n",
              "      <td>0.159660</td>\n",
              "      <td>...</td>\n",
              "      <td>0.276868</td>\n",
              "      <td>-0.192429</td>\n",
              "      <td>0.479095</td>\n",
              "      <td>-0.490182</td>\n",
              "      <td>-0.047360</td>\n",
              "      <td>0.195639</td>\n",
              "      <td>0.449680</td>\n",
              "      <td>-0.357008</td>\n",
              "      <td>0.268580</td>\n",
              "      <td>-0.383713</td>\n",
              "      <td>-0.233643</td>\n",
              "      <td>0.471439</td>\n",
              "      <td>-0.463445</td>\n",
              "      <td>-0.179418</td>\n",
              "      <td>-0.450622</td>\n",
              "      <td>-0.113225</td>\n",
              "      <td>0.236259</td>\n",
              "      <td>-0.162548</td>\n",
              "      <td>0.408056</td>\n",
              "      <td>0.338547</td>\n",
              "      <td>0.255864</td>\n",
              "      <td>0.656144</td>\n",
              "      <td>0.092981</td>\n",
              "      <td>-0.167417</td>\n",
              "      <td>-0.405711</td>\n",
              "      <td>-0.321657</td>\n",
              "      <td>-0.452151</td>\n",
              "      <td>0.110185</td>\n",
              "      <td>-0.151644</td>\n",
              "      <td>-0.191850</td>\n",
              "      <td>-0.141714</td>\n",
              "      <td>-0.131141</td>\n",
              "      <td>0.172552</td>\n",
              "      <td>-0.160140</td>\n",
              "      <td>0.132825</td>\n",
              "      <td>0.047903</td>\n",
              "      <td>0.087631</td>\n",
              "      <td>0.056238</td>\n",
              "      <td>0.043282</td>\n",
              "      <td>0.153107</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 832 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         x0        x1        x2  ...      x829      x830      x831\n",
              "0  0.366254 -0.602537  0.237168  ... -0.176145 -0.575897 -0.226159\n",
              "2  0.432092  0.458436 -0.147386  ... -0.381353 -0.778377 -0.086109\n",
              "4  0.167169 -0.361734  0.396267  ... -0.320239  0.080176  0.040857\n",
              "5 -0.351395  0.289232  0.293071  ... -0.001046 -0.372933  0.545064\n",
              "6 -0.042825 -0.546083  0.238445  ...  0.056238  0.043282  0.153107\n",
              "\n",
              "[5 rows x 832 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cJge2LpdfYl"
      },
      "source": [
        "# 4. Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2OzXhunlpw_"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "from numpy.random import randint\n",
        "randomNumber = randint(100000000)\n",
        "XGB_reg = XGBRegressor(n_jobs=-1, objective ='reg:squarederror', n_estimator=100, learning_rate=0.1,subsample=0.8, colsample_bytree=0.8, reg_alpha=0.2, reg_lambda=0.2, gamma=0.1, random_state=randomNumber)\n",
        "XGB_reg_fit = XGB_reg.fit(X_data_2, y_data)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "4F2aZPMYs1iN",
        "outputId": "f797428c-7789-44f3-96dc-0b01c568c710"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# feature importance\n",
        "plt.hist(np.abs(XGB_reg.feature_importances_))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([726.,  76.,  17.,   2.,   4.,   1.,   4.,   1.,   0.,   1.]),\n",
              " array([0.        , 0.00296845, 0.00593691, 0.00890536, 0.01187381,\n",
              "        0.01484226, 0.01781072, 0.02077917, 0.02374762, 0.02671608,\n",
              "        0.02968453], dtype=float32),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_xj1xjOvKnE"
      },
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "threshold=0.003\n",
        "XGB_reg_sfm = SelectFromModel(XGB_reg, threshold=threshold).fit(X_data_2, y_data)\n",
        "X_data_3 = XGB_reg_sfm.transform(X_data_2)\n",
        "X_test_3 = XGB_reg_sfm.transform(X_test_1)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tvpdGaFvDYt",
        "outputId": "c42f9c3c-1c81-4e31-db75-a32974976718"
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_data_3, y_data, test_size=0.2, random_state=1)\n",
        "print(\"X_train shape: \", X_train.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:  (920, 105)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCSg-Br-dfYl"
      },
      "source": [
        "## 4.1 Using SelectKBest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvEVldnRdfYm",
        "outputId": "6ed01307-834e-43d2-da63-4df82d8c79f1"
      },
      "source": [
        "# selector = SelectKBest(score_func=chi2, k=85)\n",
        "# selector = selector.fit(X_data_2.abs(), y = y_data)\n",
        "# X_data_3 = selector.transform(X_data_2)\n",
        "# X_test_3 = selector.transform(X_test_2)\n",
        "# print(\"X_data shape\", X_data_3.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_data shape (1151, 85)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UkYCOG3dfYm"
      },
      "source": [
        "## 4.2 Using SelectFromModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1H4pXiBdfYn"
      },
      "source": [
        "# For RFR\n",
        "# estimator2 = RandomForestRegressor()\n",
        "# selector2 = SelectFromModel(estimator2, max_features=150, threshold=\"mean\")\n",
        "# selector2 = selector2.fit(X_data_2, y_data)\n",
        "# X_data_3 = selector2.transform(X_data_2)\n",
        "# X_test_3 = selector2.transform(X_test_2)\n",
        "\n",
        "# For SVR\n",
        "# estimator2 = KernelRidge()\n",
        "# selector2 = SelectFromModel(estimator2, max_features=150, threshold=\"mean\", importance_getter='dual_coef_')\n",
        "# selector2 = selector2.fit(X_data_2, y_data.ravel())\n",
        "# X_data_3 = selector2.transform(X_data_2)\n",
        "# X_test_3 = selector2.transform(X_test_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07UKviPbdfYo"
      },
      "source": [
        "## 4.3 Using RFE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbcVlpF0dfYo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "c03da61f-293d-49d4-b836-e24f09308e2b"
      },
      "source": [
        "# Make RFE faster\n",
        "selector = SelectKBest(score_func=chi2, k=300)\n",
        "selector = selector.fit(X_data_2.abs(), y = y_data)\n",
        "X_data_2_c = selector.transform(X_data_2)\n",
        "X_test_2_c = selector.transform(X_test_2)\n",
        "\n",
        "estimator = RandomForestRegressor(n_estimators=320, min_samples_split=3)\n",
        "selector = RFE(estimator, step=5, n_features_to_select=85, verbose=2)\n",
        "selector = selector.fit(X_data_2_c, y_data.ravel())\n",
        "X_data_3 = selector.transform(X_data_2_c)\n",
        "X_test_3 = selector.transform(X_test_2_c)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting estimator with 300 features.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-359c0654651f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features_to_select\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m85\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data_2_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mX_data_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data_2_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mX_test_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_2_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;31m# Get coefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7OMQzHgdfYp"
      },
      "source": [
        "# estimator = RandomForestRegressor(n_estimators=200, min_samples_split=3)\n",
        "# selector = RFE(estimator, step=5, n_features_to_select=85, verbose=2)\n",
        "# selector = selector.fit(X_data_2, y_data.ravel())\n",
        "# X_data_3 = selector.transform(X_data_2)\n",
        "# X_test_3 = selector.transform(X_test_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC3iZFJ7dfYp"
      },
      "source": [
        "## 4.4 Using RFECV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKnAaHDydfYq"
      },
      "source": [
        "selector = SelectKBest(score_func=chi2, k=400)\n",
        "selector = selector.fit(X_data_2.abs(), y = y_data)\n",
        "X_data_2_c = selector.transform(X_data_2)\n",
        "X_test_2_c = selector.transform(X_test_2)\n",
        "\n",
        "estimator = RandomForestRegressor(n_estimators=320, min_samples_split=3)\n",
        "selector = RFECV(estimator, step=10, cv=5, n_features_to_select=85, verbose=2)\n",
        "selector = selector.fit(X_data_2_c, y_data.ravel())\n",
        "X_data_3 = selector.transform(X_data_2_c)\n",
        "X_test_3 = selector.transform(X_test_2_c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxlxT0E1dfYq"
      },
      "source": [
        "# 5. Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMwnxwaidfYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da110516-277e-4ddf-91f1-2b7748b2d2f3"
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_data_3, y_data, test_size=0.2, random_state=1)\n",
        "print(\"X_train shape: \", X_train.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:  (920, 105)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzzNaenaPY_U"
      },
      "source": [
        "## XGB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6-FkHiq2JnL",
        "outputId": "29cdd8e5-222d-4a62-a230-0e7b38230272"
      },
      "source": [
        "XGB_reg_fit = XGB_reg.fit(X_train, y_train)\n",
        "y_pred = XGB_reg.predict(X_valid)\n",
        "r_score = r2_score(y_valid, y_pred)\n",
        "print(\"Validation score:\", r_score)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.5837417724034193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMVwbmTRPc4-"
      },
      "source": [
        "## ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDunWMYpPfVI"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORyrtHMjPgca"
      },
      "source": [
        "firANN = keras.models.Sequential()\n",
        "firANN.add(keras.layers.Dense(16,input_dim=X_train.shape[1], kernel_regularizer = regularizers.l2(1), kernel_initializer='RandomUniform'))\n",
        "firANN.add(keras.layers.Dense(16, activation = \"relu\",\n",
        "               kernel_initializer='he_uniform',\n",
        "               kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
        "               bias_regularizer=regularizers.l2(1e-4),\n",
        "               activity_regularizer=regularizers.l2(1e-5)\n",
        "               ))\n",
        "firANN.add(keras.layers.Dropout(0.2))\n",
        "firANN.add(keras.layers.Dense(16, activation = \"relu\",\n",
        "               kernel_initializer='he_uniform',\n",
        "               kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
        "               bias_regularizer=regularizers.l2(1e-4),\n",
        "               activity_regularizer=regularizers.l2(1e-5)\n",
        "               ))\n",
        "firANN.add(keras.layers.Dropout(0.2))\n",
        "firANN.add(keras.layers.Dense(16, activation = \"relu\",\n",
        "               kernel_initializer='he_uniform',\n",
        "               kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
        "               bias_regularizer=regularizers.l2(1e-4),\n",
        "               activity_regularizer=regularizers.l2(1e-5)\n",
        "               ))\n",
        "firANN.add(keras.layers.Dropout(0.2))\n",
        "firANN.add(keras.layers.Dense(1))\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "ejd-xbQdPnrp",
        "outputId": "bb07527e-3956-4859-9f26-8331bbb0d86b"
      },
      "source": [
        "firANN.compile(loss = \"mean_squared_error\",\n",
        "              optimizer = keras.optimizers.Adam(0.001), metrics=[coeff_determination])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-33a0e2d0d75c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m firANN.compile(loss = \"mean_squared_error\",\n\u001b[0;32m----> 2\u001b[0;31m               optimizer = keras.optimizers.Adam(0.001), metrics=[coeff_determination])\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'coeff_determination' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz8y5gxJPoav"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsXBu6YKPrhk",
        "outputId": "2aca1ac5-6570-4063-de2b-9390ff53bd18"
      },
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=4, restore_best_weights=True)\n",
        "history = firANN.fit(X_train, y_train, batch_size=32, epochs=30, \n",
        "                    validation_data=(X_valid, y_valid), \n",
        "                    callbacks=[early_stopping_cb])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "29/29 [==============================] - 2s 17ms/step - loss: 5026.7637 - val_loss: 4695.7886\n",
            "Epoch 2/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 4974.2646 - val_loss: 4607.6572\n",
            "Epoch 3/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 4732.1206 - val_loss: 4058.9031\n",
            "Epoch 4/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 3651.8994 - val_loss: 2467.2097\n",
            "Epoch 5/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 2265.8308 - val_loss: 2049.9707\n",
            "Epoch 6/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 1953.4274 - val_loss: 1832.1820\n",
            "Epoch 7/30\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 1855.1940 - val_loss: 1558.4904\n",
            "Epoch 8/30\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 1539.9625 - val_loss: 1276.9010\n",
            "Epoch 9/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 1244.9579 - val_loss: 982.8246\n",
            "Epoch 10/30\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 1018.9473 - val_loss: 749.4024\n",
            "Epoch 11/30\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 907.5256 - val_loss: 526.2418\n",
            "Epoch 12/30\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 753.4624 - val_loss: 382.4697\n",
            "Epoch 13/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 626.5998 - val_loss: 307.7353\n",
            "Epoch 14/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 580.3217 - val_loss: 250.5247\n",
            "Epoch 15/30\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 569.9359 - val_loss: 222.5740\n",
            "Epoch 16/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 541.6642 - val_loss: 177.3317\n",
            "Epoch 17/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 493.8558 - val_loss: 174.1726\n",
            "Epoch 18/30\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 495.8764 - val_loss: 157.2199\n",
            "Epoch 19/30\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 513.3362 - val_loss: 138.7913\n",
            "Epoch 20/30\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 501.0663 - val_loss: 122.7609\n",
            "Epoch 21/30\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 443.3223 - val_loss: 137.0115\n",
            "Epoch 22/30\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 440.9664 - val_loss: 127.8354\n",
            "Epoch 23/30\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 424.9047 - val_loss: 108.3501\n",
            "Epoch 24/30\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 416.2176 - val_loss: 107.0466\n",
            "Epoch 25/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 440.3659 - val_loss: 107.4771\n",
            "Epoch 26/30\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 397.1123 - val_loss: 100.1747\n",
            "Epoch 27/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 418.4612 - val_loss: 104.4168\n",
            "Epoch 28/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 419.6331 - val_loss: 110.9473\n",
            "Epoch 29/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 377.6280 - val_loss: 136.5607\n",
            "Epoch 30/30\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 376.0050 - val_loss: 107.7799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biFUuFOEZ5QK",
        "outputId": "be9ff53b-29b9-4d98-a810-2e72a94983d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        }
      },
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(12, 8))\n",
        "plt.grid(True)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHHhn_0aaXSq",
        "outputId": "5d305314-2385-4f93-a323-48fdfa8e4040",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred = firANN.predict(X_valid)\n",
        "r_score = r2_score(y_valid, y_pred)\n",
        "print(\"Validation score:\", r_score)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.02620318052363435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHIMBLLWdfYr"
      },
      "source": [
        "## 5.1 KernelRidgeRegression\n",
        "Not good at all. Best score ~0.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU8Q7CETdfYr"
      },
      "source": [
        "# model = KernelRidge()\n",
        "# parameters = {'alpha':[0.01, 0.05, 0.1, 0.2, 0.5, 0.8, 1.0, 3.0, 5.0], 'kernel':['chi2', 'rbf', 'sigmoid', 'laplacian'], 'gamma':[0.1, 1, 5, 10]}\n",
        "# grid = GridSearchCV(model, parameters, scoring='r2', cv=5, verbose=3, n_jobs=-1)\n",
        "# grid.fit(X_train, y_train.ravel())\n",
        "# print(grid.best_estimator_)\n",
        "# print(grid.best_score_)\n",
        "\n",
        "# y_pred = grid.predict(X_valid)\n",
        "# r_score = r2_score(y_valid, y_pred)\n",
        "# print(\"Validation score:\", r_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FPMn0jOdfYr"
      },
      "source": [
        "## 5.2 ExtraTreesRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zthBRwH_dfYs"
      },
      "source": [
        "# model = ExtraTreesRegressor()\n",
        "# parameters = {'n_estimators':[100, 125, 150, 175, 200, 300, 325, 350,400], 'min_samples_split':[2, 3, 4]}\n",
        "# grid = GridSearchCV(model, parameters, scoring='r2', cv=5, verbose=3, n_jobs=-1)\n",
        "# grid.fit(X_train, y_train)\n",
        "# print(grid.best_estimator_)\n",
        "# print(grid.best_score_)\n",
        "\n",
        "# y_pred = grid.predict(X_valid)\n",
        "# r_score = r2_score(y_valid, y_pred)\n",
        "# print(\"Validation score:\", r_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQGOgd3OdfYs"
      },
      "source": [
        "## 5.3 RandomForestRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSshk4rtdfYs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "bef9a9b3-4f09-4ba4-9086-e16a6aacc9d3"
      },
      "source": [
        "model = RandomForestRegressor()\n",
        "parameters = {'n_estimators':[200, 300, 325, 350, 400, 430, 450, 500], 'min_samples_split':[2, 3, 4, 5]}\n",
        "grid = GridSearchCV(model, parameters, scoring='r2', verbose=1, cv=5, n_jobs=-1)\n",
        "grid.fit(X_train, y_train.ravel())\n",
        "print(grid.best_estimator_)\n",
        "print(grid.best_score_)\n",
        "\n",
        "y_pred = grid.predict(X_valid)\n",
        "r_score = r2_score(y_valid, y_pred)\n",
        "print(\"Validation score:\", r_score)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-4380346b3860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m325\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m350\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m430\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m450\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min_samples_split'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdH88kvcdfYt"
      },
      "source": [
        "# estimator2 = grid.best_estimator_\n",
        "# selector2 = SelectFromModel(estimator2, max_features=150, threshold=\"mean\")\n",
        "# selector2 = selector2.fit(X_data_2, y_data.ravel())\n",
        "# X_data_3 = selector2.transform(X_data_2)\n",
        "# X_test_3 = selector2.transform(X_test_2)\n",
        "\n",
        "# X_train, X_valid, y_train, y_valid = train_test_split(X_data_3, y_data, test_size=0.2, random_state=1)\n",
        "# print(\"X_train shape: \", X_train.shape)\n",
        "\n",
        "# rfr = estimator2.fit(X_train, y_train.ravel())\n",
        "# y_pred = rfr.predict(X_valid)\n",
        "# r_score = r2_score(y_valid,y_pred)\n",
        "# print(\"Validation score:\", r_score)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfalK3gldfYt"
      },
      "source": [
        "rfr = estimator.fit(X_train, y_train)\n",
        "y_pred = rfr.predict(X_valid)\n",
        "r_score = r2_score(y_valid,y_pred)\n",
        "print(\"Validation score:\", r_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJqkvh0ldfYt"
      },
      "source": [
        "## 5.4 SupportVectorRegression\n",
        "score ~ 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWnZvVUydfYu"
      },
      "source": [
        "# model = SVR()\n",
        "# parameters = {'kernel':['sigmoid', 'rbf', 'poly'], 'degree':[3, 4, 5, 7, 9], 'gamma':[0.005, 0.01, 0.05, 0.1, 1], 'C':[0.01, 0.05, 0.1, 1, 2]}\n",
        "# grid = GridSearchCV(model, parameters, scoring='r2', cv=5, verbose=1, n_jobs=8)\n",
        "# grid.fit(X_train, y_train.ravel())\n",
        "# print(grid.best_estimator_)\n",
        "# print(grid.best_score_)\n",
        "\n",
        "# y_pred = grid.predict(X_valid)\n",
        "# r_score = r2_score(y_valid, y_pred)\n",
        "# print(\"Validation score:\", r_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xetUrkygdfYu"
      },
      "source": [
        "# 6. Export the prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vORmNt23dfYu"
      },
      "source": [
        "# rfr = grid.best_estimator_\n",
        "rfr = XGB_reg.fit(X_data_3, y_data.ravel())\n",
        "\n",
        "y_test = rfr.predict(X_test_3)\n",
        "data_id = X_df['id']\n",
        "result = list(zip(data_id,y_test))\n",
        "result_table = pd.DataFrame(data = result, columns = ['id', 'y'])\n",
        "result_table.tail()\n",
        "result_table.to_csv('rfr7.csv', index = False)"
      ],
      "execution_count": 59,
      "outputs": []
    }
  ]
}